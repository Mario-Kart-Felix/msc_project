{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '2009', '2010', '255w', 'able', 'accuracy', 'accurate', 'accurately', 'ad', 'address', 'addresses', 'adjunct', 'after', 'ago', 'airport', 'all', 'along', 'already', 'also', 'alternatives', 'although', 'always', 'amazed', 'amazing', 'amazingly', 'an', 'and', 'any', 'anyone', 'are', 'areas', 'around', 'arrival', 'arrive', 'arrived', 'as', 'aside', 'assumed', 'astray', 'at', 'attention', 'august', 'away', 'barrell', 'battery', 'be', 'beats', 'because', 'been', 'being', 'believe', 'best', 'better', 'blocked', 'blown', 'boat', 'bottom', 'bought', 'built', 'business', 'but', 'by', 'calculate', 'calculation', 'can', 'capability', 'cars', 'changing', 'close', 'closest', 'closing', 'comes', 'completely', 'connection', 'cons', 'constantly', 'continue', 'cracker', 'database', 'date', 'day', 'depending', 'destination', 'detailed', 'determined', 'determing', 'did', 'difficult', 'directions', 'disappoint', 'disappointed', 'discovered', 'displays', 'does', 'doesn', 'don', 'down', 'downfall', 'driving', 'easily', 'easy', 'enough', 'errors', 'especially', 'estimate', 'estimated', 'estimates', 'etc', 'even', 'every', 'everything', 'everytime', 'everywhere', 'exact', 'excellent', 'explain', 'extremely', 'fact', 'familiar', 'fantastic', 'far', 'fast', 'features', 'few', 'fewer', 'find', 'first', 'for', 'found', 'friendly', 'friends', 'from', 'function', 'games', 'garmin', 'generally', 'get', 'getting', 'give', 'gives', 'giving', 'glad', 'glitch', 'go', 'golden', 'good', 'got', 'gps', 'graphics', 'great', 'guide', 'guilty', 'had', 'has', 'have', 'haven', 'having', 'heard', 'highly', 'home', 'honest', 'hospital', 'how', 'if', 'immediate', 'in', 'inaccuracy', 'inaccurate', 'inexpensive', 'info', 'information', 'inside', 'intend', 'interest', 'interface', 'internal', 'interstate', 'into', 'intuitive', 'is', 'isn', 'it', 'item', 'its', 'knew', 'know', 'latest', 'leave', 'led', 'less', 'level', 'like', 'limit', 'limits', 'line', 'little', 'll', 'loaded', 'loads', 'local', 'location', 'locations', 'logical', 'looking', 'lot', 'lunch', 'machines', 'maine', 'make', 'mall', 'map', 'maps', 'may', 'me', 'mileage', 'minute', 'miss', 'mistake', 'mode', 'money', 'morning', 'most', 'mounted', 'moving', 'much', 'my', 'name', 'navigate', 'navigator', 'navigon', 'necessary', 'new', 'nice', 'northern', 'not', 'notch', 'nothing', 'nuvi', 'obstacle', 'of', 'on', 'once', 'one', 'ones', 'online', 'only', 'operate', 'operation', 'or', 'original', 'other', 'out', 'owned', 'part', 'paved', 'paying', 'pedestrian', 'places', 'play', 'please', 'plenty', 'plus', 'point', 'pois', 'poor', 'posted', 'practiced', 'pretty', 'product', 'program', 'provided', 'provides', 'quickest', 'quickly', 'quirks', 'quite', 'rather', 're', 'read', 'ready', 'really', 'reason', 'recalculate', 'recalculating', 'received', 'reliable', 'remotest', 'review', 'road', 'roads', 'route', 'routing', 'rural', 'satellite', 'say', 'says', 'screen', 'see', 'seem', 'seems', 'set', 'shopping', 'side', 'signs', 'simplicity', 'sirloin', 'small', 'so', 'software', 'some', 'sometimes', 'soon', 'speed', 'stars', 'stated', 'steak', 'stop', 'straight', 'street', 'streets', 'take', 'tees', 'tell', 'telling', 'tells', 'that', 'the', 'them', 'then', 'there', 'these', 'they', 'thing', 'this', 'those', 'though', 'thrown', 'thus', 'time', 'times', 'to', 'told', 'too', 'top', 'town', 'trangle', 'traps', 'travel', 'traveled', 'travelling', 'tried', 'trip', 'turn', 'uncannily', 'unit', 'units', 'up', 'updated', 'use', 'used', 'user', 'using', 'usually', 've', 'vehicle', 'very', 'visiting', 'voice', 'wanted', 'was', 'wasn', 'way', 'we', 'website', 'weeks', 'well', 'what', 'when', 'where', 'whereever', 'which', 'while', 'who', 'will', 'with', 'within', 'worked', 'would', 'yards', 'years', 'yet', 'you', 'your']\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.27336869 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-98fdd4e363e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mgenerate_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-98fdd4e363e5>\u001b[0m in \u001b[0;36mgenerate_wordcloud\u001b[1;34m(text, stopwords)\u001b[0m\n\u001b[0;32m     12\u001b[0m                           \u001b[0mrelative_scaling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                           \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;31m# set or space-separated string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                           ).generate(text)\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#    generate_from_frequencies()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m         \"\"\"\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \"\"\"\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mr\"\\w[\\w']+\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;31m# remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "\n",
    "def generate_wordcloud(text, stopwords=STOPWORDS): # optionally add: stopwords=STOPWORDS and change the arg below\n",
    "    wordcloud = WordCloud( background_color='white',\n",
    "                          relative_scaling = 1.0,\n",
    "                          stopwords = stopwords # set or space-separated string\n",
    "                          ).generate(text)\n",
    "#    generate_from_frequencies()\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    #plt.show()\n",
    "#    plt.savefig(r'RelinquishmentReports/4386-p517.pdf' + '\\\\' + report.replace('.pdf', '.jpg'))\n",
    "\n",
    "# Import the data set \n",
    "path = r'../data/raw/OpinosisDataset1.0_0/topics/'\n",
    "allFiles = glob.glob(path + \"/*.data\")\n",
    "reviews = list()\n",
    "tf_idf = dict()\n",
    "for file_ in allFiles:\n",
    "    with open(file_, \"r\") as f:\n",
    "        review = split_sentences(f.read())\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(review)\n",
    "        features = vectorizer.get_feature_names()\n",
    "        tfidf_array = tfidf_matrix.toarray()\n",
    "#        df = pd.DataFrame(tfidf_matrix.toarray(), columns = vectorizer.get_feature_names())\n",
    "        print(features)\n",
    "        print(tfidf_array)\n",
    "        generate_wordcloud(review).generate()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
